{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213ff76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from sampling.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from sampling import progressive_sample,random_sample,randu_progo,progu_rando\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import Dense,LSTM, Input, Activation\n",
    "from keras.layers import Convolution2D,MaxPooling2D, Dropout , Flatten,  Conv1D, MaxPooling1D\n",
    "from keras.layers import ConvLSTM2D, BatchNormalization, MaxPooling3D,Bidirectional, GRU \n",
    "from keras import Model\n",
    "from keras import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78563619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Neethu_ZU\\Phase2\\code_data\n"
     ]
    }
   ],
   "source": [
    "cd E:\\Neethu_ZU\\Phase2\\code_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e51748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the dataset file of extracted features\n",
    "data_row = pd.read_csv('data/dataset_exam_proctor_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed919c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>vertical_head_movement</th>\n",
       "      <th>horizontal_head_movement</th>\n",
       "      <th>vertical_eye_movement</th>\n",
       "      <th>horizontal_eye_movement</th>\n",
       "      <th>mouth_height</th>\n",
       "      <th>mouth_threshold</th>\n",
       "      <th>identity</th>\n",
       "      <th>blinking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>-34</td>\n",
       "      <td>1.015873</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.804738</td>\n",
       "      <td>7.933333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-35</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.804738</td>\n",
       "      <td>7.933333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-35</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.804738</td>\n",
       "      <td>7.933333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-31</td>\n",
       "      <td>1.187500</td>\n",
       "      <td>0.632353</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>7.943039</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  vertical_head_movement  horizontal_head_movement  \\\n",
       "0   1      0                       9                       -34   \n",
       "1   1      0                       7                       -35   \n",
       "2   1      0                       7                       -35   \n",
       "3   1      0                       7                       -31   \n",
       "4   1      0                       7                       -31   \n",
       "\n",
       "   vertical_eye_movement  horizontal_eye_movement  mouth_height  \\\n",
       "0               1.015873                 0.614286      0.804738   \n",
       "1               1.071429                 0.614286      0.804738   \n",
       "2               1.071429                 0.614286      0.804738   \n",
       "3               1.000000                 0.628571      0.000000   \n",
       "4               1.187500                 0.632353      1.414214   \n",
       "\n",
       "   mouth_threshold  identity  blinking  \n",
       "0         7.933333         1         0  \n",
       "1         7.933333         1         0  \n",
       "2         7.933333         1         0  \n",
       "3         8.166667         1         0  \n",
       "4         7.943039         1         1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_row.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b84e91fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale data\n",
    "\n",
    "df_row_scaled = data_row.copy()\n",
    "scalar = MinMaxScaler()\n",
    "df_row_scaled[['vertical_head_movement', 'horizontal_head_movement',\n",
    "            'vertical_eye_movement', 'horizontal_eye_movement', 'mouth_height',\n",
    "            'mouth_threshold']] = scalar.fit_transform(df_row_scaled[['vertical_head_movement', 'horizontal_head_movement',\n",
    "                                            'vertical_eye_movement', 'horizontal_eye_movement', 'mouth_height',\n",
    "                                           'mouth_threshold']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2c2143f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neethu Venugopal\\AppData\\Local\\Continuum\\anaconda3\\envs\\py_img\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "# seperate data and label of each user and save it\n",
    "group = df_row_scaled.groupby(['id'])\n",
    "label_df = group.first()[['label']].reset_index()\n",
    "label_df.to_csv('data/user_label.csv', index= False)\n",
    "data_series = [df_row_scaled.iloc[group.groups[i],2:10].values.tolist() for i in list(group.groups.keys())]\n",
    "np.save(\"sampled_data/input_video_series.npy\",data_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86730cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_series = np.load('sampled_data/input_video_series.npy', allow_pickle=True)\n",
    "label_data = pd.read_csv('data/user_label.csv')\n",
    "label_array = np.array(label_data[['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae4977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make samples with equal length sequences using Random undersample oversample\n",
    "data_series_eq = []\n",
    "Y = []\n",
    "for i,seq in enumerate(data_series):\n",
    "    video_frac,l = random_sample(seq,100,label_array[i],sub_samples = None)\n",
    "    if(len(video_frac)>0): \n",
    "        data_series_eq.extend(video_frac)\n",
    "        Y.extend(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350fb50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = \"100\"\n",
    "repeat = \"dyn\"\n",
    "with open('sampled_data/random_data_v2_eq_vol/inpdata_' +seq_length+'_'+ repeat+'.npy', 'wb') as f:\n",
    "    np.save(f, np.array(data_series_eq))\n",
    "with open('sampled_data/random_data_v2_eq_vol/labeldata_' +seq_length+'_'+ repeat+'.npy', 'wb') as l:\n",
    "    np.save(l, np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc8eb50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sampled_data/random_data_v2/inpdata_100_dyn.npy', 'rb') as f:\n",
    "        X = np.load(f)\n",
    "with open('sampled_data/random_data_v2/labeldata_100_dyn.npy', 'rb') as l:\n",
    "        Y = np.load(l)\n",
    "SHAPE = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0b1c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM model\n",
    "def create_model():\n",
    "    inp_data = Input(shape = (SHAPE[1],SHAPE[2]))\n",
    "    lstm1 = LSTM(100, return_sequences = True )(inp_data)\n",
    "    flat1 = (Flatten())(lstm1)\n",
    "    dense1 = Dense(128, activation='relu')(flat1)\n",
    "    output = Dense(1, activation='sigmoid')(dense1)\n",
    "    model = Model(inputs=inp_data, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f4d1084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "X = X.reshape(SHAPE[0], 1, SHAPE[1],SHAPE[2])\n",
    "def create_model():\n",
    "    inp_data = Input(shape = (1, SHAPE[1],SHAPE[2]))\n",
    "    cnn1 = (Convolution2D(32, (3, 3), activation='relu', data_format='channels_first'))(inp_data)\n",
    "    pool1 = (MaxPooling2D(pool_size=(2,2)))(cnn1)\n",
    "    drop1 = (Dropout(0.25))(pool1)\n",
    "    cnn2 = (Convolution2D(32, (3, 3),activation='relu'))(drop1)\n",
    "    pool2 = (MaxPooling2D(pool_size=(2,2)))(cnn2)\n",
    "    drop2 = (Dropout(0.25))(pool2) \n",
    "    flat = (Flatten())(drop2)\n",
    "    dense1 = (Dense(64, activation='relu'))(flat)\n",
    "    drop3 = (Dropout(0.5))(dense1)\n",
    "    output = (Dense(1, activation='sigmoid'))(drop3)\n",
    "    model = Model(inputs=inp_data, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN-LSTM model\n",
    "def create_model():\n",
    "    inp_data = Input(shape = (SHAPE[1], SHAPE[2]))\n",
    "    conv2 = (Conv1D(filters=32, kernel_size=3, activation='relu'))(inp_data)\n",
    "    pool1 = (MaxPooling1D(pool_size=2))(conv2)\n",
    "    lstm1 = (LSTM(100, return_sequences = True))(pool1)\n",
    "    flat2 = (Flatten())(lstm1)\n",
    "    drop2 = (Dropout(0.5))(flat2)\n",
    "    dense1 = (Dense(128, activation='relu'))(drop2)\n",
    "    output = (Dense(1, activation='sigmoid'))(dense1)\n",
    "    model = Model(inputs=inp_data, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925989a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvLSTM\n",
    "n_length = 4\n",
    "n_steps = int(SHAPE[1]/4)\n",
    "X = X.reshape((SHAPE[0], n_steps,1, n_length, SHAPE[2]))\n",
    "def create_model():\n",
    "    inp_data = Input(shape = (n_steps, 1, n_length, SHAPE[2]))\n",
    "    convlstm1 = (ConvLSTM2D(filters=100, kernel_size=(1,2), activation='relu', data_format='channels_first', return_sequences = True))(inp_data)\n",
    "    batch1 = (BatchNormalization())(convlstm1)\n",
    "    pool2 = (MaxPooling3D())(batch1)\n",
    "    drop1 = (Dropout(0.2))(pool2)\n",
    "    flat1 = (Flatten(data_format='channels_first'))(drop1)\n",
    "    dense1 = (Dense(64, activation='relu'))(flat1)\n",
    "    output = (Dense(1, activation='sigmoid'))(dense1)\n",
    "    model = Model(inputs=inp_data, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c075c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv-BiGRU\n",
    "X = X.reshape(SHAPE[0], SHAPE[1], SHAPE[2])\n",
    "def create_model():\n",
    "    inp_data = Input(shape = (SHAPE[1], SHAPE[2]))\n",
    "    conv1 = (Conv1D(filters=32, kernel_size=(2)))(inp_data)\n",
    "    activ1 = (Activation('relu'))(conv1)\n",
    "    drop2 = (Dropout(0.25))(activ1)\n",
    "    gru1 = (Bidirectional(GRU(32, return_sequences = True, activation='relu')))(drop2)\n",
    "    flat1 = (Flatten())(gru1)\n",
    "    dense1 = (Dense(64 , activation='relu'))(flat1)\n",
    "    dense1 = (Dense(32 , activation='relu'))(dense1)\n",
    "    dense1 = (Dense(16 , activation='relu'))(dense1)\n",
    "    drop4 = (Dropout(0.4))(dense1)\n",
    "    output = (Dense(1, activation='sigmoid'))(drop4)\n",
    "    model = Model(inputs=inp_data, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4638844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation using cross validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "cvscores_auc = []\n",
    "cvscores_acc = []\n",
    "cvscores_prec = []\n",
    "cvscores_rec = []\n",
    "for train, test in kfold.split(X, Y):\n",
    "  # create model\n",
    "\tmodel = create_model()\n",
    "\tmodel.summary()\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam',metrics=[metrics.AUC(name = 'auc'), \n",
    "                                                                        metrics.BinaryAccuracy(name = 'accuracy'),\n",
    "                                                                        metrics.Precision(name = 'precision'),\n",
    "                                                                        metrics.Recall(name = 'recall')])\n",
    "\t# Fit the model\n",
    "\tprint(len(X[train]),len(X[test]))\n",
    "\tes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\thistory = model.fit(X[train], Y[train], epochs=70, batch_size=16,  validation_data=(X[test], Y[test]),callbacks=[es], verbose=1)\n",
    "\t# evaluate the model\n",
    "\tscores = model.evaluate(X[test], Y[test], verbose=1)\n",
    "\tprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\tprint(\"%s: %.2f%%\" % (model.metrics_names[2], scores[2]*100))\n",
    "\tprint(\"%s: %.2f%%\" % (model.metrics_names[3], scores[3]*100))\n",
    "\tprint(\"%s: %.2f%%\" % (model.metrics_names[4], scores[4]*100))\n",
    "\tcvscores_auc.append(scores[1] * 100)\n",
    "\tcvscores_acc.append(scores[2] * 100)\n",
    "\tcvscores_prec.append(scores[3] * 100)\n",
    "\tcvscores_rec.append(scores[4] * 100)\n",
    "print(\"%s:%.2f%% (+/- %.2f%%)\" % (model.metrics_names[1], np.mean(cvscores_auc), np.std(cvscores_auc)))\n",
    "print(\"%s:%.2f%% (+/- %.2f%%)\" % (model.metrics_names[2],np.mean(cvscores_acc), np.std(cvscores_acc)))\n",
    "print(\"%s:%.2f%% (+/- %.2f%%)\" % (model.metrics_names[3], np.mean(cvscores_prec), np.std(cvscores_prec)))\n",
    "print(\"%s:%.2f%% (+/- %.2f%%)\" % (model.metrics_names[4], np.mean(cvscores_rec), np.std(cvscores_rec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b3703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation using train-test split\n",
    "#split train and test data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2, shuffle = True)\n",
    "model = create_model()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[metrics.AUC(name = 'auc'), \n",
    "                                                                        metrics.BinaryAccuracy(name = 'accuracy'),\n",
    "                                                                        metrics.Precision(name = 'precision'),\n",
    "                                                                        metrics.Recall(name = 'recall')])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "history = model.fit(X_train, y_train,batch_size=16,epochs=70, verbose=1, validation_data=(X_valid, y_valid),shuffle = True, callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c440a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
